<HTML>

<HEAD>
<STYLE>
    body {
        width: 80ch;
        text-align: justify;
    }
    #content {
        counter-reset: h3counter;
    }
    #content h3:before {
        content: counter(h3counter) ".\0000a0\0000a0";
        counter-increment: h3counter;
    }
	.code {
		font-family: monospace;
	}
    li {
        margin-top: 0.5em;
    }
    dt {
        margin-top: 1em;
    }
</STYLE>
</HEAD>

<BODY>

<DIV id="toc">
<H3>Table of content:</H3>
<OL>
<LI> Files-map</LI>
<LI> Set-up environment</LI>
<LI> Quick start</LI>
<LI> Reduction semantics</LI>
<LI> Reduction strategy</LI>
<LI> Refocusing</LI>
</OL>
</DIV>


<DIV id="content">

<H3>Files-map</H3>
<CODE>
<TABLE>

<TR><TH>MODULE</TH><TH/><TH>FILE</TH></TR>

<TR>
<TD>abstract_machine</TD>
<TD>-></TD>
<TD>abstract_machine/abstract_machine.v</TD>
</TR> 

<TR>
<TD>abstract_machine_facts</TD>
<TD>-></TD>
<TD>abstract_machine/abstract_machine_facts.v</TD>
</TR> 

<TR>
<TD>reduction_semantics</TD>
<TD>-></TD>
<TD>reduction_semantics/reduction_semantics.v</TD>
</TR> 

<TR>
<TD>reduction_strategy</TD>
<TD>-></TD>
<TD>reduction_semantics/reduction_strategy.v</TD>
</TR> 

<TR>
<TD>refocusing_semantics</TD>
<TD>-></TD>
<TD>refocusing/refocusing_semantics.v</TD>
</TR>

<TR>
<TD>refocusing_machine</TD>
<TD>-></TD>
<TD>refocusing/refocusing_machine.v</TD>
</TR>

<TR>
<TD>refocusing_machine_facts</TD>
<TD>-></TD>
<TD>refocusing/refocusing_machine_facts.v</TD>
</TR>

</TABLE>
</CODE>

<H3>Set-up environment</H3>

<P>To compile the library one may use the <CODE>make</CODE> command in 
the main directory.</P>

<P>To remove old binaries one may use the <CODE>make clean</CODE> command in
the main directory.</P>
</P>

<P>To run Coq with the library loaded one may call <CODE>coqtop</CODE> with 
the parameter <CODE>-R [dir_with_the_compiled_library] Top</CODE>.</P>


<H3>Quick start</H3>

<P>To generate a machine one may use <CODE>SloppyRefEvalApplyMachine</CODE> or 
<CODE>RefEvalApplyMachine</CODE> functor from <CODE>refocusing_machine</CODE> 
module. 
Both functors apply to modules implementing a reduction 
semantics with an additional computable DFS strategy, an explicitly stated 
refocusing procedure, and the latter requires also one predicate to be 
computable. Namely, the functors need arguments of <CODE>RED_REF_SEM</CODE> and 
<CODE>PRECISE_RED_REF_SEM</CODE> signatures, respectively, from 
<CODE>refocusing_semantics</CODE> module. 
To save some work one may use functors <CODE>RedRefSem</CODE> and 
<CODE>PreciseRedRefSem</CODE> from 
the same module to generate these arguments out of a not-full reduction 
semantic module <CODE>R</CODE>&mdash;signature: <CODE>PRE_REF_SEM</CODE> or 
<CODE>PRE_PRECISE_REF_SEM</CODE>&mdash;and 
a strategy module&mdash;signature: <CODE>REF_STRATEGY R</CODE>&mdash;where 
the signatures are given 
again in <CODE>refocusing_semantics</CODE>. The signatures included in those 
mentioned 
above can be found in <CODE>reduction_strategy</CODE> module. For a use case 
cf. <CODE>lam_no.v</CODE> 
example.</P>

<P>The <CODE>SloppyRefEvalApplyMachine</CODE> functor generates an abstract 
machine that may 
contain extra invalid states, which, however, are not accessible from valid 
states. The <CODE>RefEvalApplyMachine</CODE> functor generates a proper machine,
which 
states are the subset of valid states from the sloppy machine, but in 
consequence manipulating the result machine involves extensive work with 
dependent types. We provide both functors to give a choice between easier </P>

<P>The tracing theorem&mdash;for proper machines&mdash;and some equivalent 
lemmas&mdash;for 
sloppy ones&mdash;are provided in the module 
<CODE>refocusing_machine_facts</CODE>. The module
contains also <CODE>safe_region_map</CODE> theorems allowing to map 
reduction-closed sets 
of terms to transition-closed sets of machine states. To simulate a generated 
machine one may use <CODE>n_steps</CODE> function from 
<CODE>abstract_machine_facts</CODE>.</P>

<H3>Reduction semantics</H3>

<P>Generally, our reduction semantics are composed from: a set of terms, 
a grammar of 
contexts with possibly multiple kinds of holes, and a contraction, which is 
a family of binary relations on terms indexed by the hole kinds. The grammar of 
contexts describes the reduction contests, which should be distinguished from
arbitrary contexts understood as "terms with a hole".</P>

<P>The implementation have additional requirements, as follows.</P>

<OL>

<LI>The kinds of holes must be non-terminals from the grammar of contexts.</LI>

<LI>For each context non-terminal <CODE>k</CODE> the production
<CODE>k->[ ]<SUB>k</SUB></CODE> must be in the grammar of contexts.</LI>

<LI>All other productions must contain a non-terminal in their right sides.</LI>

<LI>There cannot be epsilon transitions in the grammar of contexts, i.e., 
productions <CODE>k->k'</CODE>.</LI>

<LI>Contractions need to be partial functions.</LI>

</OL>

<P>Note that any common reduction semantics can be normalized to a form that
satisfies this conditions.</P>

<P>Our implementation also requires additional definitions, as follows.</P>

<OL>

<LI>A set of elementary contexts (context frames) needs to be explicitly given, 
and all contexts <CODE>C</CODE> such that there exists a production in 
the grammar of
contexts that rewrites a non-terminal symbol to some <CODE>C[k]</CODE> must 
be in this set.</LI>

<!--LI>the grammar of contexts needs to be total
w.r.t. elementary contexts, i.e., for all non-terminals <CODE>k</CODE> and 
elementary contexts <CODE>ec</CODE> there must exist a production that
rewrites <CODE>k</CODE> to some <CODE>ec[k']</CODE>,</LI--> 

<LI>A family of sets of potential redexes indexed by hole kinds needs to be 
explicitly given. A potential redex is a term that can be contracted or
a stuck-term, that is, a term that represents an invalid computation, like 
a division by zero.</LI>

<LI>A family of sets of values indexed by hole kinds needs to be explicitly
given. Values of a kind <CODE>k</CODE> represent terms <CODE>t</CODE> 
that 
are irreducible in any reduction context <CODE>C</CODE> with the hole 
<CODE>[ ]<SUB>k</SUB></CODE></LI> and represent proper results of a computation, 
i.e., there does not exist a context 
<CODE>C'</CODE> and a potential redex <CODE>r</CODE> such that 
<CODE>t=C'[r]</CODE> and <CODE>C[C']</CODE> is a reduction context.</LI> 

<LI>A set of additional non-terminal symbols that will be used as sinks in
the grammar of contexts needs to be given. A sink symbol is needed if
the language of reduction contexts is hybrid, that is,
productions are not total w.r.t. element contexts&mdash;specifically, if there
exists a non-terminal <CODE>k</CODE> and an elementary context <CODE>ec</CODE> 
such that there is no production that rewrites <CODE>k</CODE> to some
<CODE>ec[k']</CODE>. Semantically, we do not require more then one sink, but
one may want to have more of them for some implementational tricks.</LI>

</OL>

<P>Reduction semantics are represented by modules of the <CODE>RED_SEM</CODE>
signature form <CODE>reduction_semantics</CODE> module. The module must
implement the following parameters.</P>

<DL>

<DT class="code">term          : Set</DT><DD></DD>

<DT class="code">elem_context  : Set</DT><DD>the type of elementary contexts 
mentioned above</DD>

<DT class="code">ckind         : Set</DT>
<DD>the type of context non-terminal symbols in the grammar of contexts and
sink symbols. We call its elements context kinds.</DD>

<DT class="code">ckind_trans   : ckind -> elem_context -> ckind</DT>
<DD>a representation of non-terminal productions in the grammar, i.e., 
productions different then <CODE>k->[ ]<SUB>k</SUB></CODE>. Specifically, 
<CODE>ckind_trans k ec = k'</CODE> iff there is a production that rewrites
<CODE>k</CODE> to <CODE>ec[k']</CODE> or there is no production that rewrites
<CODE>k</CODE> to any <CODE>ec[k"]</CODE> and <CODE>k'</CODE> is a sink.
</DD>

<DT class="code">elem_plug     : term -> elem_context -> term</DT>
<DD>a function that determinates a result of plugging a term into 
an elementary context.</DD>

<DT class="code">redex         : ckind -> Set</DT>
<DD>the type of representations of potential redexes mentioned above</DD>

<DT class="code">value         : ckind -> Set</DT>
<DD>the type of representations of values mentioned above</DD>

<DT class="code">redex_to_term : forall {k}, redex k -> term</DT>
<DD>a semantics of potential redexes</DD>

<DT class="code">value_to_term : forall {k}, value k -> term</DT>
<DD>a semantics of values</DD>

<DT class="code">init_ckind    : ckind</DT>
<DD>a starting symbol in the grammar of contexts</DD>

<DT class="code">dead_ckind    : ckind -> Prop</DT>
<DD>a set of sink non-terminals</DD>

<DT class="code">contract      : forall {k}, redex k -> option term</DT>
<DD>a representation of contraction partial functions mentioned above</DD>

</DL>

<P>Besides of these, a <CODE>RED_SEM</CODE> module needs to have a bunch of 
additional definitions, which should be copied from the signature, and
a bunch of lemmas that guaranties that the reduction semantics is well-formed,
e.g., <CODE>value_redex : forall {k},
forall (v : value k) (r : redex k), value_to_term v <> redex_to_term r</CODE>,
which guaranties that values and potential redexes are disjoint.</P>

<P>An important definition is the one for contexts, parametrized by two context 
kinds. Reduction contexts are represented by the context of a type parametrized
by kinds that are not sinks. The other contexts are invalid and we should
think about them as they would not exists. Particularly, they occur in
the implementation only because of implementational reasons.</P>

<P>Each pair of non-terminal symbols that are not sinks determinates 
a syntactic category of contexts. The first kind determines a starting symbol 
in the grammar of contexts from which contexts in this category are derived.
The second determinates a kind of holes that all contexts in this category
contain.</P>

<P>Note that contexts are represented in the implementation by their 
derivations.</P>

<!--
  Infix "+>"           := ckind_trans (at level 50, left associativity).
  Notation "ec :[ t ]" := (elem_plug t ec) (at level 0).
  Coercion  value_to_term : value >-> term.
  Coercion  redex_to_term : redex >-> term.


  (* context k1 k2 - contexts of kind k1 (derivated from k1) with a hole of kind k2. 
                     Contexts are represented by reversed derivations in the grammar.
                     E.g., if a context is derivated by a sequence of productions
                     k1 -> ec1 k2, k2 -> ec2 k3, k3 -> ec3 k4, k4 -> [], then it is 
                     represented by the list  (ec3, k3), (ec2, k2), (ec1, k1)  of 
                     the type  context k1 k4.
                     The second elements in the pairs are implicite. *)
  Inductive context (k1 : ckind) : ckind -> Set :=
  | empty : context k1 k1
  | ccons : forall (ec : elem_context) {k2}, context k1 k2 -> context k1 (k2+>ec).
  Arguments empty {k1}. Arguments ccons {k1} _ {k2} _.
  Notation "[.]"      := empty.
  Notation "[.]( k )" := (@empty k).
  Infix    "=:"       := ccons (at level 60, right associativity).

  (* Note: Contexts are reversed, because during evaluation by refocusing we always 
     access the elem. context nearest to the hole of a context. *)

  (* Definition: The hole of a context is called >dead< if its kind is a sink symbol. *)

  (* Definition: A context is called >proper< if its hole is not dead. 
     (Context with dead holes are contexts that cannot be generated in the orginal
     grammar.) *)

  Fixpoint compose {k1 k2} (c0 : context k1 k2) 
                      {k3} (c1 : context k3 k1) : context k3 k2 := 
      match c0 in context _ k2' return context k3 k2' with
      | [.]     => c1
      | ec=:c0' => ec =: compose c0' c1
      end.
  Infix "~+" := compose (at level 60, right associativity).

  Fixpoint plug (t : term) {k1 k2} (c : context k1 k2) : term :=
      match c with
      | [.]    => t 
      | ec=:c' => plug ec:[t] c'
      end.
  Notation "c [ t ]" := (plug t c) (at level 0).

  Definition immediate_ec ec t := exists t', ec:[t'] = t.

  (* decomp k - decomposition of a term t from the symbol k to a redex.
     d_red r c  means: t = c[r].
     d_val v    means: t has no redexes and so it is a value, t = v. *)
  Inductive decomp k : Set :=
  | d_red : forall {k'}, redex k' -> context k k' -> decomp k
  | d_val : value k -> decomp k.
  Arguments d_val {k} _. Arguments d_red {k} {k'} _ _.

  Definition decomp_to_term {k} (d : decomp k) :=
      match d with
      | d_val v   => value_to_term v
      | d_red r c => c[r]
      end.
  Coercion decomp_to_term : decomp >-> term.

  Definition dec (t : term) k (d : decomp k) : Prop := 
      ~dead_ckind k /\ t = d.

  Definition reduce k t1 t2 := 
      exists {k'} (c : context k k') (r : redex k') t,  dec t1 k (d_red r c) /\
          contract r = Some t /\ t2 = c[t].

  Instance lrws : LABELED_REWRITING_SYSTEM ckind term :=
  { ltransition := reduce }.

  Instance rws : REWRITING_SYSTEM term :=
  { transition := reduce init_ckind }.

  (* Definition: A decomposition c[t] is empty if c is empty. *)
  (* Definition: A decomposition c[t] is proper if c is proper. *)



  Axioms
  (init_ckind_alive : 
       ~dead_ckind init_ckind)

  (death_propagation :                                                       forall k ec,
       dead_ckind k -> dead_ckind (k+>ec))

  (proper_death :                                                               forall k,
       dead_ckind k -> ~ exists (r : redex k), True)

  (value_to_term_injective :                                 forall {k} (v v' : value k),
       value_to_term v = value_to_term v' -> v = v')

  (redex_to_term_injective :                                 forall {k} (r r' : redex k),
       redex_to_term r = redex_to_term r' -> r = r')

  (* The following axiom, somehow, relates our representation of contexts to the 
     real eval. contexts, but generally we can instantiate the module with 
     elem. contexts that do not represent real elem. contexts and so not
     every module of this signature is a proper. *)
  (elem_plug_injective1 :                                                forall ec t0 t1,
       ec:[t0] = ec:[t1] -> t0 = t1)

  (value_trivial1 :                                                    forall {k} ec {t},
       forall v : value k,  ~dead_ckind (k+>ec)  ->  ec:[t] = v -> 
           exists (v' : value (k+>ec)), t = v')

  (value_redex :                                                              forall {k},
       forall (v : value k) (r : redex k), value_to_term v <> redex_to_term r)

  (decompose :                                                                forall t k,
       ~dead_ckind k -> exists d : decomp k, dec t k d).


  Class SafeKRegion (k : ckind) (P : term -> Prop) :=
  { 
      preservation :                                                        forall t1 t2,
          P t1  ->  k |~ t1 → t2  ->  P t2;
      progress :                                                               forall t1,
          P t1  ->  (exists (v : value k), t1 = v) \/ (exists t2, k |~ t1 → t2)
  }.

End RED_SEM.
</CODE-->

<H3>Reduction strategy</H3>

<P>A DFS reduction/evaluation strategy is an order 
in which the generated machine ought to search for a redex 
in a term. To apply our refocusing one needs to define such a strategy.</P>

<P>In the library we do this by setting a family
of strict orders, &lt;<SUB>k,t</SUB>, on elementary contexts indexed by 
kinds and terms. 
Each elementary context that is a prefix of some term determines a position
in this term, i.e., if <CODE>t = ec[t']</CODE>, then the elementary context 
<CODE>ec</CODE> appoints the subterm <CODE>t'</CODE> in the term <CODE>t</CODE>.
Thus, by setting an order on elementary contexts that are prefixes of a term,
we determinate an order on positions in the term. Because we can have
multiple substrategies in which a term ought to be considered (multiple
kinds of holes in which a term may be considered), 
we can have a different order per 
each kind. So, if <CODE>ec<SUB>1</SUB></CODE> &lt;<SUB>k,t</SUB> 
<CODE>ec<SUB>2</SUB></CODE>, then it means 
<CODE>t = ec<SUB>1</SUB>[t<SUB>1</SUB>] = 
ec<SUB>2</SUB>[t<SUB>2</SUB>]</CODE> and 
searching <CODE>t</CODE> w.r.t. the <CODE>k</CODE>-substrategy 
should check the subterm <CODE>t<SUB>2</SUB></CODE> 
before going to <CODE>t<SUB>1</SUB></CODE>.</P>

<P>The basic interface describing our strategies is
<CODE>RED_STRATEGY</CODE>.</P>

<P>The operations of taking the greatest element and the predecessor for
each of these orders have to be
computable partial functions.
Also, we need a computable operation
that determines if a term is a potential redex or 
a value after scanning all subterms in it. 
If we want to generate a machine that 
operates in small steps all these
functions need to be small. In the library
all these operations are given at once in terms of
elementary decompositions.</P>

<P>The interface responsible for elementary decompositions
is <CODE>RED_STRATEGY_STEP</CODE>.</P>

<!--elementary contexts are comparable, i.e., 
$ec_1 \leq_{k,t} ec_2$ or $ec_1 \geq_{k,t} ec_2$
iff
$k \to \plug{k_1}{ec_1}$ and $k \to \plug{k_2}{ec_2}$ are
productions in the grammar of contexts, and
$ec_1,\: ec_2$ are prefixes of $t$, i.e., 
$t = \plug{t_1}{ec_1} = \plug{t_2}{ec_2}$.
The order determines that 
The introduced orders are called a \emph{DFS evaluation strategy} in our
refocusing as they describe a depth-first search order of evaluation that
turns back from a term only if it has checked all possible subterms and it has
found that the term is a value. This is captured by another 
%required property
condition, i.e., if $ec_1 <_{k,t} ec_2$, then $t = \plug{t_2}{ec_2}$ and
$t_2 \in \mathcal{V}_k$.

.-->

<H3>Refocusing</H3>

</DIV>

</BODY>
</HTML>